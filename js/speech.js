// js/speech.js
import * as dom from './dom.js';
import { showAlert } from './ui.js';
import * as api from './api.js'; // [â˜…] í‰ê°€ë¥¼ ìœ„í•´ api ëª¨ë“ˆ import

let recognition = null;
let isRecognizing = false;
let currentRecognitionTargetInput = null;
let currentRecognitionMicButton = null;
let currentEvaluationText = null; // [â˜…] í‰ê°€í•  ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥ìš©

/**
 * [â˜…] APIë¡œë¶€í„° ë°›ì€ ë°œìŒ í‰ê°€ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * @param {string} original - ì›ë³¸ í…ìŠ¤íŠ¸
 * @param {string} user - ì‚¬ìš©ì ë°œìŒ í…ìŠ¤íŠ¸
 */
async function handlePronunciationResult(original, user) {
    console.log(`Sending to API for evaluation: Original: "${original}", User said: "${user}"`);
    try {
        // 1. API í˜¸ì¶œ
        const result = await api.evaluatePronunciation(original, user);
        
        // 2. ê²°ê³¼ íŒŒì‹±
        let evalData;
        if (result.candidates && result.candidates[0]?.content?.parts?.[0]) {
            const evalText = result.candidates[0].content.parts[0].text.trim().replace(/^```json\s*|\s*```$/g, '');
            evalData = JSON.parse(evalText);
        } else {
            throw new Error("Invalid API response structure.");
        }

        // 3. í”¼ë“œë°± í‘œì‹œ
        if (evalData && evalData.feedback) {
            // is_correct ê°’ì— ë”°ë¼ ì•„ì´ì½˜ ì¶”ê°€
            const icon = evalData.is_correct ? "ğŸ‰" : "ğŸ¤”";
            showAlert(`${icon} ${evalData.feedback}`);
        } else {
            throw new Error("API response missing 'feedback' key.");
        }
        
    } catch (error) {
        console.error("Pronunciation evaluation error:", error);
        showAlert(`í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`);
    }
}

/**
 * Web Speech APIë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
 */
export function initializeSpeechRecognition() {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (SpeechRecognition) {
        recognition = new SpeechRecognition();
        recognition.lang = 'zh-CN';
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        // [â˜… ìˆ˜ì •] onresult ë¡œì§ ë³€ê²½
        recognition.onresult = (event) => {
            console.log("Speech Recognition Result:", event.results);
            const speechResult = event.results[0][0].transcript;
            console.log("Recognized Text:", speechResult);

            const targetInput = currentRecognitionTargetInput;
            const evalText = currentEvaluationText;

            if (targetInput) {
                // --- ëª¨ë“œ 1: INPUT (ê¸°ì¡´ ë¡œì§) ---
                console.log("Mode: Input");
                targetInput.value = speechResult;
                setTimeout(() => {
                    if (targetInput === dom.chatInput) {
                        console.log("Auto-submitting chat message...");
                        if (dom.sendChatBtn) dom.sendChatBtn.click();
                    } else if (targetInput.id.startsWith('practice-input-')) {
                        console.log("Auto-submitting practice answer...");
                        const index = targetInput.id.split('-').pop();
                        const checkButton = document.getElementById(`check-practice-btn-${index}`);
                        if (checkButton && checkButton.style.display !== 'none') {
                           checkButton.click();
                        } else {
                            console.warn("Auto-submit skipped: Check button not found or not visible for", targetInput.id);
                        }
                    }
                }, 150);
            } else if (evalText) {
                // --- ëª¨ë“œ 2: EVALUATION (ìƒˆ ë¡œì§) ---
                console.log("Mode: Evaluation");
                handlePronunciationResult(evalText, speechResult);
            } else {
                 console.warn("Recognition result received but no target (Input or Evaluation) was set.");
            }
        };

        recognition.onspeechend = () => {
            console.log("Speech Recognition: Speech has stopped being detected.");
        };

        recognition.onnomatch = () => {
            console.log("Speech Recognition: No match found.");
            showAlert('ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
        };

        recognition.onerror = (event) => {
            console.error("Speech Recognition Error:", event.error, event.message);
            if (event.error !== 'no-speech' && event.error !== 'aborted' && event.error !== 'not-allowed') {
                 showAlert(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.`);
            } else if (event.error === 'not-allowed') {
                 showAlert('ë§ˆì´í¬ ì‚¬ìš© ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
            }
        };

         // [â˜… ìˆ˜ì •] onend ë¡œì§ ë³€ê²½
         recognition.onend = () => {
            console.log("Speech Recognition: Service ended.");
            if (currentRecognitionMicButton) {
                currentRecognitionMicButton.classList.remove('is-recording');
            }
            isRecognizing = false;
            currentRecognitionTargetInput = null;
            currentRecognitionMicButton = null;
            currentEvaluationText = null; // [â˜…] í‰ê°€ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        };

        console.log("Speech Recognition initialized for zh-CN.");

    } else {
        console.warn('Web Speech API is not supported in this browser.');
        showAlert('í˜„ì¬ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
    }
}

/**
 * ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.
 */
export function stopRecognition() {
    if (recognition && isRecognizing) {
        console.log("Stopping recognition...");
        recognition.stop();
    }
}

/**
 * [â˜…] ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•˜ë©° ìŒì„± ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤.
 * @param {HTMLElement} button - í´ë¦­ëœ ë§ˆì´í¬ ë²„íŠ¼
 * @param {HTMLElement} targetInput - (Input ëª¨ë“œ) ê²°ê³¼ë¥¼ ì…ë ¥í•  input ìš”ì†Œ
 * @param {string} originalText - (Eval ëª¨ë“œ) í‰ê°€í•  ì›ë³¸ í…ìŠ¤íŠ¸
 */
function startRecognition(button, targetInput, originalText) {
     try {
        console.log("Starting recognition...");
        currentRecognitionTargetInput = targetInput;
        currentEvaluationText = originalText;
        currentRecognitionMicButton = button;
        recognition.start();
        button.classList.add('is-recording');
        isRecognizing = true;
    } catch(e) {
         console.error("Speech recognition start error:", e);
         if (e.name === 'NotAllowedError' || e.name === 'SecurityError') {
             showAlert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ í—ˆìš©í•´ì£¼ì„¸ìš”.");
         }
         else if (e.name === 'InvalidStateError') {
             console.warn("Attempted to start recognition while already active. Ignoring.");
         }
         else {
             showAlert("ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
         }
         
         if(button) button.classList.remove('is-recording');
         
         if (e.name !== 'InvalidStateError') {
             isRecognizing = false;
             currentRecognitionTargetInput = null;
             currentRecognitionMicButton = null;
             currentEvaluationText = null; // [â˜…] ì´ˆê¸°í™”
         }
    }
}

/**
 * [â˜…] ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ë¥¼ í† ê¸€ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * @param {HTMLElement} button - í´ë¦­ëœ ë§ˆì´í¬ ë²„íŠ¼
 * @param {object} options - { targetInput: HTMLElement | null, originalText: string | null }
 */
export function toggleRecognition(button, { targetInput = null, originalText = null }) {
    if (!recognition) {
         showAlert('ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•Šê±°ë‚˜ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
         console.log("Recognition not available or not initialized.");
        return;
    }
    
    if (isRecognizing) {
        // ì¸ì‹ì´ ì§„í–‰ ì¤‘ì¼ ë•Œ
        recognition.stop();
        
        // ë§Œì•½ ë‹¤ë¥¸ ë²„íŠ¼ì„ ëˆ„ë¥¸ ê±°ë¼ë©´, ì ì‹œ í›„ ìƒˆ ì¸ì‹ì„ ì‹œì‘
        if (currentRecognitionMicButton !== button) {
             setTimeout(() => startRecognition(button, targetInput, originalText), 300);
        }
    } else {
        // ì¸ì‹ì´ êº¼ì ¸ìˆì„ ë•Œ -> ìƒˆ ì¸ì‹ ì‹œì‘
         startRecognition(button, targetInput, originalText);
    }
}